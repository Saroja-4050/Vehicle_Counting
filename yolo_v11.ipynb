{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvpCeHp0kYlI",
        "outputId": "7672eae7-739e-4ef4-dfec-c5b86832fa29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.108-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.108-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.108 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path=\"yolo11n-seg.pt\"):\n",
        "    \"\"\"\n",
        "    Detect vehicles in an image using YOLOv11 segmentation model and save the annotated output.\n",
        "\n",
        "    Args:\n",
        "        input_image_path (str): Path to the input image.\n",
        "        output_image_path (str): Path where the annotated image will be saved.\n",
        "        model_path (str): Path or name of the YOLOv11 segmentation model (default: 'yolo11n-seg.pt').\n",
        "    \"\"\"\n",
        "    # Load the YOLOv11 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)  # Automatically downloads weights if not present locally\n",
        "\n",
        "    # Read the input image\n",
        "    if not os.path.exists(input_image_path):\n",
        "        raise FileNotFoundError(f\"Input image {input_image_path} not found.\")\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Perform inference with a set confidence threshold\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                # Filter for vehicles: COCO class IDs 2 (car) and 7 (truck)\n",
        "                if int(cls) in [2, 7]:\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to match image\n",
        "                    mask = mask > 0.5  # Binarize the mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify your input and output image paths\n",
        "    input_path = \"input1.jpeg\"  # Replace with your actual input image path\n",
        "    output_path = \"output_detected_seg.jpg\"  # Output image path\n",
        "\n",
        "    # Check if the input image exists before proceeding\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9VURgdlnT4c",
        "outputId": "6af48677-d071-42a7-aaae-1629ea8303f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolo11n-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.90M/5.90M [00:00<00:00, 44.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input1.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input1.jpeg: 320x640 1 person, 21 cars, 5 trucks, 380.7ms\n",
            "Speed: 16.3ms preprocess, 380.7ms inference, 211.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 27\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (0, 852, 342, 1279)\n",
            "Detection: Vehicle 0.84 (Class: 2), Box: (0, 1107, 528, 1682)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (349, 873, 779, 1286)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (805, 923, 1235, 1290)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (2928, 521, 3255, 772)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (484, 411, 910, 707)\n",
            "Detection: Vehicle 0.72 (Class: 2), Box: (1265, 459, 1547, 708)\n",
            "Detection: Vehicle 0.70 (Class: 2), Box: (3089, 905, 3559, 1378)\n",
            "Detection: Vehicle 0.66 (Class: 2), Box: (3159, 407, 3436, 623)\n",
            "Detection: Vehicle 0.66 (Class: 2), Box: (916, 461, 1239, 704)\n",
            "Detection: Vehicle 0.57 (Class: 2), Box: (1477, 108, 1686, 291)\n",
            "Detection: Vehicle 0.57 (Class: 2), Box: (2571, 326, 2844, 600)\n",
            "Detection: Vehicle 0.56 (Class: 2), Box: (1228, 101, 1460, 287)\n",
            "Detection: Vehicle 0.56 (Class: 2), Box: (2251, 430, 2558, 747)\n",
            "Detection: Vehicle 0.53 (Class: 2), Box: (2722, 139, 2938, 337)\n",
            "Detection: Vehicle 0.48 (Class: 2), Box: (2472, 154, 2674, 313)\n",
            "Detection: Vehicle 0.47 (Class: 2), Box: (1726, 289, 1881, 554)\n",
            "Detection: Vehicle 0.46 (Class: 2), Box: (193, 414, 509, 685)\n",
            "Detection: Vehicle 0.45 (Class: 2), Box: (1736, 84, 1942, 291)\n",
            "Detection: Vehicle 0.42 (Class: 7), Box: (2469, 150, 2674, 325)\n",
            "Detection: Vehicle 0.42 (Class: 2), Box: (1949, 465, 2210, 734)\n",
            "Detection: Vehicle 0.41 (Class: 2), Box: (2597, 959, 3059, 1344)\n",
            "Detection: Vehicle 0.40 (Class: 7), Box: (2725, 137, 2935, 332)\n",
            "Detection: Vehicle 0.37 (Class: 7), Box: (1950, 466, 2212, 736)\n",
            "Detection: Vehicle 0.37 (Class: 7), Box: (1473, 108, 1693, 290)\n",
            "Detection: Vehicle 0.37 (Class: 7), Box: (1215, 102, 1459, 286)\n",
            "Masks detected: 27\n",
            "Output image saved to output_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path=\"yolo11n-seg.pt\"):\n",
        "    \"\"\"\n",
        "    Detect vehicles in an image using YOLOv11 segmentation model and save the annotated output.\n",
        "\n",
        "    Args:\n",
        "        input_image_path (str): Path to the input image.\n",
        "        output_image_path (str): Path where the annotated image will be saved.\n",
        "        model_path (str): Path or name of the YOLOv11 segmentation model (default: 'yolo11n-seg.pt').\n",
        "    \"\"\"\n",
        "    # Load the YOLOv11 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)  # Automatically downloads weights if not present locally\n",
        "\n",
        "    # If you have a GPU and want to ensure usage:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Read the input image\n",
        "    if not os.path.exists(input_image_path):\n",
        "        raise FileNotFoundError(f\"Input image {input_image_path} not found.\")\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Perform inference with:\n",
        "    #  - Confidence threshold (tune as needed, e.g. 0.25, 0.3, or 0.4)\n",
        "    #  - Larger input size for better detection of small objects (imgsz=1280)\n",
        "    #  - GPU usage if available (device=device)\n",
        "    results = model.predict(\n",
        "        source=image,\n",
        "        conf=0.3,      # Adjust confidence threshold here\n",
        "        iou=0.45,\n",
        "        verbose=True,\n",
        "        device=device,\n",
        "        imgsz=1280     # Larger resolution for more accurate detection of small vehicles\n",
        "    )\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                # Filter for vehicles: COCO class IDs 2 (car) and 7 (truck)\n",
        "                if int(cls) in [2, 7]:\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    # If you prefer, you can skip resizing to keep the original mask resolution\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
        "                    mask = mask > 0.5  # Binarize the mask\n",
        "                    color = (\n",
        "                        random.randint(0, 255),\n",
        "                        random.randint(0, 255),\n",
        "                        random.randint(0, 255),\n",
        "                    )\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(\n",
        "            annotated_image, label, (x1, label_y),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2\n",
        "        )\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify your input and output image paths\n",
        "    input_path = \"input1.jpeg\"  # Replace with your actual input image path\n",
        "    output_path = \"output_detected_seg_1.jpg\"  # Output image path\n",
        "\n",
        "    # Adjust if you have a different YOLOv11 model variant or path\n",
        "    model_path = \"yolo11n-seg.pt\"\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjx9fOBKo0bv",
        "outputId": "81f61f3e-f212-4443-9e83-5814d4119c96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolo11n-seg.pt\n",
            "Using device: cpu\n",
            "Input image loaded: input1.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "0: 640x1280 2 persons, 22 cars, 703.2ms\n",
            "Speed: 10.0ms preprocess, 703.2ms inference, 577.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 24\n",
            "Detection: Vehicle 0.92 (Class: 2), Box: (0, 1120, 522, 1688)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (487, 422, 910, 716)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (1951, 474, 2210, 740)\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (813, 925, 1238, 1293)\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (2932, 527, 3254, 777)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (349, 877, 778, 1283)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (2569, 325, 2842, 606)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (2252, 436, 2553, 745)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (0, 858, 341, 1263)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (3088, 910, 3557, 1374)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (3159, 418, 3432, 624)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (191, 424, 558, 688)\n",
            "Detection: Vehicle 0.80 (Class: 2), Box: (1482, 115, 1701, 293)\n",
            "Detection: Vehicle 0.78 (Class: 2), Box: (1265, 459, 1550, 712)\n",
            "Detection: Vehicle 0.77 (Class: 2), Box: (1631, 285, 1885, 560)\n",
            "Detection: Vehicle 0.76 (Class: 2), Box: (916, 465, 1237, 708)\n",
            "Detection: Vehicle 0.74 (Class: 2), Box: (2477, 159, 2670, 320)\n",
            "Detection: Vehicle 0.68 (Class: 2), Box: (2718, 144, 2933, 341)\n",
            "Detection: Vehicle 0.68 (Class: 2), Box: (2644, 966, 3056, 1342)\n",
            "Detection: Vehicle 0.67 (Class: 2), Box: (1232, 108, 1456, 287)\n",
            "Detection: Vehicle 0.65 (Class: 2), Box: (1739, 80, 1942, 297)\n",
            "Detection: Vehicle 0.57 (Class: 2), Box: (395, 255, 706, 463)\n",
            "Masks detected: 24\n",
            "Output image saved to output_detected_seg_1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Df-TnD_grUjQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}