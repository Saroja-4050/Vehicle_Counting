{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O9ahc9bnFKa",
        "outputId": "e0aca556-53f8-42dd-9a02-3fe6561005d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.108-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.108-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.108 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path=\"yolov8m-seg.pt\"):\n",
        "    # Load the YOLOv8-seg model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Read the input image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Resize image to improve detection of smaller vehicles (optional)\n",
        "    # image = cv2.resize(image, (1280, 1280))\n",
        "\n",
        "    # Perform inference with a higher confidence threshold\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate all masks\n",
        "\n",
        "    # First, collect all detections and masks\n",
        "    boxes_to_draw = []\n",
        "    for result in results:\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            # Collect bounding boxes for later drawing\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # COCO class IDs: 2 = car, 7 = truck\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            # Accumulate all masks into a single mask_color array with different colors\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # Only for vehicles\n",
        "                    mask = mask.cpu().numpy()  # Convert mask to numpy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to image size\n",
        "                    mask = mask > 0.5  # Binarize the mask\n",
        "                    # Generate a random color for this mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color  # Assign random color to mask\n",
        "\n",
        "    # Blend the combined mask with the original image (30% transparency for better visibility)\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Lower transparency for clearer masks\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes on top of the blended image with adjusted label placement\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Adjust label position to avoid overlap (place above or below based on y1)\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the output image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    input_path = \"input.jpeg\"  # Replace with your input image path\n",
        "    output_path = \"parking_lot_detected_seg.jpg\"  # Output image path\n",
        "    model_path = \"yolov8m-seg.pt\"  # Use medium segmentation model\n",
        "\n",
        "    # Check if input file exists\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUuzzCdXnRmC",
        "outputId": "91ce17cd-96ff-481f-899f-a5f699c8765c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Loading model: yolov8m-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-seg.pt to 'yolov8m-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 52.4M/52.4M [00:00<00:00, 58.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input.jpeg: 320x640 1 person, 22 cars, 1277.2ms\n",
            "Speed: 15.7ms preprocess, 1277.2ms inference, 100.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 23\n",
            "Detection: Vehicle 0.93 (Class: 2), Box: (1, 1115, 524, 1684)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (810, 920, 1241, 1289)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (484, 415, 911, 709)\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (1266, 467, 1552, 707)\n",
            "Detection: Vehicle 0.87 (Class: 2), Box: (2928, 525, 3251, 775)\n",
            "Detection: Vehicle 0.87 (Class: 2), Box: (0, 847, 340, 1258)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (2566, 320, 2844, 602)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (917, 459, 1239, 704)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (355, 872, 780, 1281)\n",
            "Detection: Vehicle 0.84 (Class: 2), Box: (1950, 466, 2210, 736)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (3088, 908, 3557, 1372)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (2250, 430, 2552, 741)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (192, 417, 539, 684)\n",
            "Detection: Vehicle 0.79 (Class: 2), Box: (3156, 409, 3429, 618)\n",
            "Detection: Vehicle 0.78 (Class: 2), Box: (1632, 283, 1882, 555)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (1482, 107, 1698, 289)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (2716, 136, 2935, 335)\n",
            "Detection: Vehicle 0.72 (Class: 2), Box: (2477, 154, 2674, 310)\n",
            "Detection: Vehicle 0.71 (Class: 2), Box: (1728, 73, 1946, 291)\n",
            "Detection: Vehicle 0.65 (Class: 2), Box: (1233, 99, 1458, 283)\n",
            "Detection: Vehicle 0.61 (Class: 2), Box: (2652, 958, 3055, 1341)\n",
            "Detection: Vehicle 0.57 (Class: 2), Box: (397, 245, 703, 470)\n",
            "Masks detected: 23\n",
            "Output image saved to parking_lot_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path):\n",
        "    # Load the chosen YOLOv8 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Read the input image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Optionally, you might want to resize the image for better detection on small vehicles\n",
        "    # image = cv2.resize(image, (1280, 1280))\n",
        "\n",
        "    # Perform inference with a set confidence threshold (you can tune this value)\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result (could be multiple if processing a batch)\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # COCO class IDs for vehicles: 2=car, 7=truck\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to match the image\n",
        "                    mask = mask > 0.5  # Binarize mask with threshold\n",
        "\n",
        "                    # Generate a random color for each mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image (using 30% transparency)\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on top of the blended image\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Place the label above the box if there is space; otherwise, below the box\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: change the model_path to try different variants\n",
        "    input_path = \"input.jpeg\"   # Replace with your input image path\n",
        "    output_path = \"output_detected_seg.jpg\" # Output image path\n",
        "\n",
        "    # Change the model here: choose among \"yolov8n-seg.pt\", \"yolov8s-seg.pt\", \"yolov8m-seg.pt\", \"yolov8l-seg.pt\", \"yolov8x-seg.pt\"\n",
        "    model_path = \"yolov8n-seg.pt\"  # Example: using the nano variant\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)\n"
      ],
      "metadata": {
        "id": "IoCji5jnp4lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4afc364-155e-4781-c1b1-4ced302b2989"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolov8n-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.74M/6.74M [00:00<00:00, 19.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input.jpeg: 320x640 21 cars, 1 truck, 199.1ms\n",
            "Speed: 3.8ms preprocess, 199.1ms inference, 56.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 22\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (2926, 520, 3255, 767)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (3154, 410, 3436, 624)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (915, 462, 1240, 700)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (0, 1112, 526, 1682)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (0, 846, 341, 1262)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (354, 872, 779, 1285)\n",
            "Detection: Vehicle 0.80 (Class: 2), Box: (807, 916, 1241, 1291)\n",
            "Detection: Vehicle 0.80 (Class: 2), Box: (1265, 469, 1547, 706)\n",
            "Detection: Vehicle 0.74 (Class: 2), Box: (485, 415, 909, 705)\n",
            "Detection: Vehicle 0.74 (Class: 2), Box: (2578, 327, 2848, 594)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (1629, 300, 1877, 556)\n",
            "Detection: Vehicle 0.72 (Class: 2), Box: (1481, 110, 1688, 287)\n",
            "Detection: Vehicle 0.70 (Class: 2), Box: (2737, 142, 2939, 332)\n",
            "Detection: Vehicle 0.69 (Class: 2), Box: (3088, 906, 3558, 1379)\n",
            "Detection: Vehicle 0.67 (Class: 2), Box: (1951, 464, 2217, 733)\n",
            "Detection: Vehicle 0.67 (Class: 2), Box: (1225, 104, 1455, 278)\n",
            "Detection: Vehicle 0.63 (Class: 2), Box: (2278, 455, 2555, 742)\n",
            "Detection: Vehicle 0.63 (Class: 2), Box: (2594, 956, 3057, 1342)\n",
            "Detection: Vehicle 0.61 (Class: 2), Box: (1737, 86, 1945, 287)\n",
            "Detection: Vehicle 0.57 (Class: 2), Box: (2481, 156, 2678, 319)\n",
            "Detection: Vehicle 0.56 (Class: 2), Box: (191, 415, 535, 680)\n",
            "Detection: Vehicle 0.30 (Class: 7), Box: (1735, 84, 1946, 292)\n",
            "Masks detected: 22\n",
            "Output image saved to output_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path):\n",
        "    # Load the chosen YOLOv8 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Read the input image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Optionally, you might want to resize the image for better detection on small vehicles\n",
        "    # image = cv2.resize(image, (1280, 1280))\n",
        "\n",
        "    # Perform inference with a set confidence threshold (you can tune this value)\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result (could be multiple if processing a batch)\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # COCO class IDs for vehicles: 2=car, 7=truck\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to match the image\n",
        "                    mask = mask > 0.5  # Binarize mask with threshold\n",
        "\n",
        "                    # Generate a random color for each mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image (using 30% transparency)\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on top of the blended image\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Place the label above the box if there is space; otherwise, below the box\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: change the model_path to try different variants\n",
        "    input_path = \"input.jpeg\"   # Replace with your input image path\n",
        "    output_path = \"output_detected_seg.jpg\" # Output image path\n",
        "\n",
        "    # Change the model here: choose among \"yolov8n-seg.pt\", \"yolov8s-seg.pt\", \"yolov8m-seg.pt\", \"yolov8l-seg.pt\", \"yolov8x-seg.pt\"\n",
        "    model_path = \"yolov8s-seg.pt\"  # Example: using the nano variant\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGY77sxqpk0H",
        "outputId": "a9637ede-4562-4a35-c77b-cd70ee7f07c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolov8s-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-seg.pt to 'yolov8s-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.8M/22.8M [00:00<00:00, 46.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input.jpeg: 320x640 1 person, 17 cars, 7 trucks, 497.6ms\n",
            "Speed: 3.3ms preprocess, 497.6ms inference, 97.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 25\n",
            "Detection: Vehicle 0.90 (Class: 2), Box: (0, 1114, 525, 1690)\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (3155, 409, 3435, 621)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (917, 462, 1236, 705)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (3086, 909, 3561, 1374)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (2929, 521, 3255, 769)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (1267, 465, 1553, 707)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (811, 919, 1241, 1293)\n",
            "Detection: Vehicle 0.79 (Class: 2), Box: (0, 851, 345, 1265)\n",
            "Detection: Vehicle 0.77 (Class: 2), Box: (2568, 319, 2849, 602)\n",
            "Detection: Vehicle 0.73 (Class: 7), Box: (1233, 99, 1457, 286)\n",
            "Detection: Vehicle 0.70 (Class: 2), Box: (2251, 428, 2554, 740)\n",
            "Detection: Vehicle 0.70 (Class: 2), Box: (2477, 154, 2675, 311)\n",
            "Detection: Vehicle 0.64 (Class: 2), Box: (345, 871, 784, 1284)\n",
            "Detection: Vehicle 0.63 (Class: 7), Box: (189, 420, 543, 684)\n",
            "Detection: Vehicle 0.62 (Class: 7), Box: (392, 246, 700, 478)\n",
            "Detection: Vehicle 0.61 (Class: 2), Box: (1630, 286, 1878, 557)\n",
            "Detection: Vehicle 0.60 (Class: 2), Box: (1951, 466, 2213, 733)\n",
            "Detection: Vehicle 0.58 (Class: 7), Box: (482, 416, 906, 714)\n",
            "Detection: Vehicle 0.56 (Class: 2), Box: (2729, 142, 2936, 333)\n",
            "Detection: Vehicle 0.55 (Class: 7), Box: (1736, 74, 1943, 283)\n",
            "Detection: Vehicle 0.45 (Class: 7), Box: (2610, 961, 3059, 1340)\n",
            "Detection: Vehicle 0.45 (Class: 2), Box: (485, 417, 910, 714)\n",
            "Detection: Vehicle 0.40 (Class: 7), Box: (1487, 107, 1698, 289)\n",
            "Detection: Vehicle 0.37 (Class: 2), Box: (2617, 958, 3058, 1340)\n",
            "Masks detected: 25\n",
            "Output image saved to output_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path):\n",
        "    # Load the chosen YOLOv8 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Read the input image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Optionally, you might want to resize the image for better detection on small vehicles\n",
        "    # image = cv2.resize(image, (1280, 1280))\n",
        "\n",
        "    # Perform inference with a set confidence threshold (you can tune this value)\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result (could be multiple if processing a batch)\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # COCO class IDs for vehicles: 2=car, 7=truck\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to match the image\n",
        "                    mask = mask > 0.5  # Binarize mask with threshold\n",
        "\n",
        "                    # Generate a random color for each mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image (using 30% transparency)\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on top of the blended image\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Place the label above the box if there is space; otherwise, below the box\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: change the model_path to try different variants\n",
        "    input_path = \"input.jpeg\"   # Replace with your input image path\n",
        "    output_path = \"output_detected_seg.jpg\" # Output image path\n",
        "\n",
        "    # Change the model here: choose among \"yolov8n-seg.pt\", \"yolov8s-seg.pt\", \"yolov8m-seg.pt\", \"yolov8l-seg.pt\", \"yolov8x-seg.pt\"\n",
        "    model_path = \"yolov8l-seg.pt\"  # Example: using the nano variant\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4BCjM4Yqfvu",
        "outputId": "8b49d4f5-7f87-4df4-c890-084bc45219e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolov8l-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-seg.pt to 'yolov8l-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 88.1M/88.1M [00:02<00:00, 34.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input.jpeg: 320x640 2 persons, 22 cars, 2020.5ms\n",
            "Speed: 3.2ms preprocess, 2020.5ms inference, 50.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 24\n",
            "Detection: Vehicle 0.91 (Class: 2), Box: (0, 1113, 522, 1687)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (487, 414, 910, 708)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (0, 849, 340, 1259)\n",
            "Detection: Vehicle 0.88 (Class: 2), Box: (813, 918, 1238, 1287)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (2570, 320, 2844, 600)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (2932, 522, 3253, 773)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (193, 417, 547, 682)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (916, 455, 1237, 701)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (1264, 467, 1548, 703)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (350, 870, 778, 1280)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (3158, 410, 3432, 619)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (2256, 431, 2552, 740)\n",
            "Detection: Vehicle 0.80 (Class: 2), Box: (1948, 469, 2208, 733)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (1630, 279, 1883, 556)\n",
            "Detection: Vehicle 0.71 (Class: 2), Box: (2660, 960, 3051, 1340)\n",
            "Detection: Vehicle 0.70 (Class: 2), Box: (1483, 107, 1702, 286)\n",
            "Detection: Vehicle 0.69 (Class: 2), Box: (1231, 98, 1459, 280)\n",
            "Detection: Vehicle 0.67 (Class: 2), Box: (2720, 137, 2935, 334)\n",
            "Detection: Vehicle 0.66 (Class: 2), Box: (2474, 153, 2676, 312)\n",
            "Detection: Vehicle 0.64 (Class: 2), Box: (394, 246, 704, 482)\n",
            "Detection: Vehicle 0.62 (Class: 2), Box: (3087, 909, 3558, 1370)\n",
            "Detection: Vehicle 0.54 (Class: 2), Box: (1732, 75, 1945, 288)\n",
            "Masks detected: 24\n",
            "Output image saved to output_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def detect_vehicles_with_segmentation(input_image_path, output_image_path, model_path):\n",
        "    # Load the chosen YOLOv8 segmentation model\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Read the input image\n",
        "    image = cv2.imread(input_image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image at {input_image_path}\")\n",
        "    print(f\"Input image loaded: {input_image_path}, shape: {image.shape}\")\n",
        "\n",
        "    # Optionally, you might want to resize the image for better detection on small vehicles\n",
        "    # image = cv2.resize(image, (1280, 1280))\n",
        "\n",
        "    # Perform inference with a set confidence threshold (you can tune this value)\n",
        "    results = model.predict(source=input_image_path, conf=0.3, iou=0.45, verbose=True)\n",
        "    print(f\"Prediction completed. Number of results: {len(results)}\")\n",
        "\n",
        "    # Process results\n",
        "    annotated_image = image.copy()\n",
        "    detections_found = False\n",
        "    combined_mask_color = np.zeros_like(image, dtype=np.uint8)  # To accumulate masks\n",
        "    boxes_to_draw = []\n",
        "\n",
        "    # Loop over each result (could be multiple if processing a batch)\n",
        "    for result in results:\n",
        "        # Process bounding boxes (detections)\n",
        "        if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "            print(f\"Boxes detected: {len(result.boxes)}\")\n",
        "            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:  # COCO class IDs for vehicles: 2=car, 7=truck\n",
        "                    detections_found = True\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    label = f\"Vehicle {conf:.2f} (Class: {int(cls)})\"\n",
        "                    boxes_to_draw.append((x1, y1, x2, y2, label))\n",
        "                    print(f\"Detection: {label}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
        "\n",
        "        # Process segmentation masks for each detection\n",
        "        if hasattr(result, 'masks') and result.masks is not None:\n",
        "            print(f\"Masks detected: {len(result.masks)}\")\n",
        "            for mask, conf, cls in zip(result.masks.data, result.boxes.conf, result.boxes.cls):\n",
        "                if int(cls) in [2, 7]:\n",
        "                    mask = mask.cpu().numpy()  # Convert from tensor to NumPy array\n",
        "                    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize to match the image\n",
        "                    mask = mask > 0.5  # Binarize mask with threshold\n",
        "\n",
        "                    # Generate a random color for each mask\n",
        "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "                    combined_mask_color[mask] = color\n",
        "\n",
        "    # Blend the combined colored masks with the original image (using 30% transparency)\n",
        "    if detections_found:\n",
        "        alpha = 0.3  # Transparency for the mask\n",
        "        beta = 1.0 - alpha\n",
        "        cv2.addWeighted(annotated_image, beta, combined_mask_color, alpha, 0.0, annotated_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on top of the blended image\n",
        "    for x1, y1, x2, y2, label in boxes_to_draw:\n",
        "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        # Place the label above the box if there is space; otherwise, below the box\n",
        "        label_y = y1 - 10 if y1 - 10 > 10 else y2 + 20\n",
        "        cv2.putText(annotated_image, label, (x1, label_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    if not detections_found:\n",
        "        print(\"No vehicles detected. Try lowering the confidence threshold or fine-tuning the model.\")\n",
        "\n",
        "    # Save the annotated image\n",
        "    cv2.imwrite(output_image_path, annotated_image)\n",
        "    print(f\"Output image saved to {output_image_path}\")\n",
        "    return annotated_image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: change the model_path to try different variants\n",
        "    input_path = \"input.jpeg\"   # Replace with your input image path\n",
        "    output_path = \"output_detected_seg.jpg\" # Output image path\n",
        "\n",
        "    # Change the model here: choose among \"yolov8n-seg.pt\", \"yolov8s-seg.pt\", \"yolov8m-seg.pt\", \"yolov8l-seg.pt\", \"yolov8x-seg.pt\"\n",
        "    model_path = \"yolov8x-seg.pt\"  # Example: using the nano variant\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Input image {input_path} not found. Please provide a valid image.\")\n",
        "    else:\n",
        "        detect_vehicles_with_segmentation(input_path, output_path, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XGl38pFrVMS",
        "outputId": "b263f474-0a6e-4285-ddc4-ef280d3a600a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: yolov8x-seg.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-seg.pt to 'yolov8x-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 137M/137M [00:03<00:00, 36.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image loaded: input.jpeg, shape: (1698, 3566, 3)\n",
            "\n",
            "image 1/1 /content/input.jpeg: 320x640 1 person, 22 cars, 3471.4ms\n",
            "Speed: 3.0ms preprocess, 3471.4ms inference, 63.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Prediction completed. Number of results: 1\n",
            "Boxes detected: 23\n",
            "Detection: Vehicle 0.92 (Class: 2), Box: (811, 919, 1239, 1287)\n",
            "Detection: Vehicle 0.90 (Class: 2), Box: (486, 417, 910, 707)\n",
            "Detection: Vehicle 0.90 (Class: 2), Box: (0, 1114, 524, 1685)\n",
            "Detection: Vehicle 0.89 (Class: 2), Box: (0, 851, 340, 1258)\n",
            "Detection: Vehicle 0.87 (Class: 2), Box: (2930, 522, 3251, 773)\n",
            "Detection: Vehicle 0.87 (Class: 2), Box: (349, 871, 780, 1280)\n",
            "Detection: Vehicle 0.86 (Class: 2), Box: (916, 457, 1236, 702)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (1264, 467, 1551, 707)\n",
            "Detection: Vehicle 0.85 (Class: 2), Box: (2569, 318, 2847, 599)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (1631, 280, 1886, 553)\n",
            "Detection: Vehicle 0.83 (Class: 2), Box: (3158, 412, 3435, 619)\n",
            "Detection: Vehicle 0.82 (Class: 2), Box: (2255, 430, 2554, 742)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (2651, 962, 3054, 1339)\n",
            "Detection: Vehicle 0.81 (Class: 2), Box: (3087, 909, 3559, 1371)\n",
            "Detection: Vehicle 0.78 (Class: 2), Box: (194, 418, 536, 685)\n",
            "Detection: Vehicle 0.78 (Class: 2), Box: (2730, 136, 2936, 337)\n",
            "Detection: Vehicle 0.73 (Class: 2), Box: (2474, 150, 2673, 312)\n",
            "Detection: Vehicle 0.72 (Class: 2), Box: (1234, 99, 1458, 281)\n",
            "Detection: Vehicle 0.68 (Class: 2), Box: (1945, 467, 2213, 735)\n",
            "Detection: Vehicle 0.61 (Class: 2), Box: (1481, 107, 1701, 285)\n",
            "Detection: Vehicle 0.58 (Class: 2), Box: (1736, 75, 1946, 288)\n",
            "Detection: Vehicle 0.48 (Class: 2), Box: (393, 247, 703, 491)\n",
            "Masks detected: 23\n",
            "Output image saved to output_detected_seg.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-M1PVV9sYyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}